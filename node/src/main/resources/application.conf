# WE node settings in HOCON
# HOCON specification: https://github.com/lightbend/config/blob/master/HOCON.md
node {
  logging-level = "DEBUG"

  crypto {
    type = WAVES
    pki {
      mode = OFF
      required-oids = []
      crl-checks-enabled = false
      crl-sync-manager-settings {
        period = 2 hours
      }
    }
  }

  owner-address = ""

  # Node base directory
  directory = ${user.home}"/node"

  # Node data directory
  data-directory = ${node.directory}"/data"

  # Snapshot data directory
  snapshot-directory = ${node.data-directory}"/snapshot"

  privacy {

    replier {
      # Max parallel tasks for processing privacy data requests.
      parallelism = 10

      # The max time the read operation on the stream should perform.
      stream-timeout = 1 minute

      # The size of one partition when transferring data as a stream.
      stream-chunk-size = 1MiB

      # Maximum percentage of peers that a replier can use to send streams
      stream-max-peers-fullness-percentage = 66
    }

    # Syncs private data.
    synchronizer {
      # Data request timeout.
      request-timeout = 2 minute

      # First retry delay. With each attempt, the delay increases by 4/3.
      init-retry-delay = 5 seconds

      # After this timeout synchronizer request inventories.
      inventory-stream-timeout = 15 seconds

      # Delay after requesting peers data inventory.
      inventory-request-delay = 3 seconds

      # Time threshold for inventory broadcast. Inventory broadcast is used for new transactions to speed up the privacy subsystem.
      inventory-timestamp-threshold = 10 minutes

      # Max parallel crawling tasks count.
      crawling-parallelism = 100

      # The number of attempts that the crawler will take before the data is marked as lost.
      max-attempt-count = 24

      # Delay between attempts to process the queue of lost items.
      lost-data-processing-delay = 10 minutes

      # Max count of the chunks in the network buffer. When the limit is reached, back pressure is activated.
      network-stream-buffer-size = 10

      # Max count of failed peer adresses in cache
      failed-peers-cache-size = 100

      # Expire timeout for failed peer addresses in cache
      failed-peers-cache-expire-timeout = 10 minutes
    }

    # Aggregates inventory data of policies
    inventory-handler {
      # Max time for buffer. When time is out, the node processes all inventories in batch.
      max-buffer-time = 500ms

      # Max number of inventories in buffer. When the limit is reached, the node processes all inventories in batch.
      max-buffer-size = 100

      # Max size of inventories cache. Using this cache, the node selects only new inventories.
      max-cache-size = 100000

      # Expiration time for cache items (inventories).
      expiration-time = 5m

      # Max parallel tasks for processing inventory requests.
      replier-parallelism = 10
    }

    # Policy data responses cache
    cache {
      # Max count of elements
      max-size = 100
      # Time to expire for element if it hasn't got access during this time
      expire-after = 10m
    }

    # DB connection config
    storage {
      vendor = none
      ## for s3:
      #  url = "http://localhost:9000/"
      #  bucket = "privacy"
      #  region = "aws-global"
      #  access-key-id = "minio"
      #  secret-access-key = "minio123"
      #  path-style-access-enabled = true
      #  connection-timeout = 30s
      #  connection-acquisition-timeout = 10s
      #  max-concurrency = 200
      #  read-timeout = 0s
      #  upload-chunk-size = 5MiB

      ## for postgres:
      # schema = "public"
      # migration-dir = "db/migration"
      # profile = "slick.jdbc.PostgresProfile$"
      # upload-chunk-size = 1MiB
      # jdbc-config {
      #   url = "jdbc:postgresql://"${POSTGRES_ADDRESS}":"${POSTGRES_PORT}"/"${POSTGRES_DB}
      #   driver = "org.postgresql.Driver"
      #   user = ${POSTGRES_USER}
      #   password = ${POSTGRES_PASSWORD}
      #   connectionPool = HikariCP
      #   connectionTimeout = 5000
      #   connectionTestQuery = "SELECT 1"
      #   queueSize = 10000
      #   numThreads = 20
      # }
    }

    service {
      # Max size of request buffer. When the limit is reached, back pressure is activated.
      request-buffer-size = 10MiB

      # Max time of metadata entity accumulation
      meta-data-accumulation-timeout = 3s
    }
  }

  confidential-contracts {

    data-directory = ${node.directory}"/confidential-data"

    replier {
      # Max parallel tasks for processing confidential data requests.
      parallelism = 10
    }

    cache {
      # Max count of elements
      max-size = 100
      # Time to expire for element if it hasn't got access during this time
      expire-after = 10m
    }

    # Aggregates inventory data of confidential contracts
    inventory-handler {
      # Max time for buffer. When time is out, the node processes all inventories in batch.
      max-buffer-time = 500ms

      # Max number of inventories in buffer. When the limit is reached, the node processes all inventories in batch.
      max-buffer-size = 100

      # Max size of inventories cache. Using this cache, the node selects only new inventories.
      max-cache-size = 100000

      # Expiration time for cache items (inventories).
      expiration-time = 5m

      # Max parallel tasks for processing inventory requests.
      replier-parallelism = 10
    }

    # Syncs confidential data.
    synchronizer {
      # Data request timeout.
      request-timeout = 2 minute

      # First retry delay. With each attempt, the delay increases by 4/3.
      init-retry-delay = 5 seconds

      # After this timeout synchronizer request inventories.
      inventory-stream-timeout = 15 seconds

      # Delay after requesting peers data inventory.
      inventory-request-delay = 3 seconds

      # Time threshold for inventory broadcast. Inventory broadcast is used for new transactions to speed up the confidential data support subsystem.
      inventory-timestamp-threshold = 10 minutes

      # Max parallel crawling tasks count.
      crawling-parallelism = 100

      # The number of attempts that the crawler will take before the data is marked as lost.
      max-attempt-count = 24

      # Delay between attempts to process the queue of lost items.
      lost-data-processing-delay = 10 minutes

      # Max count of failed peer addresses in cache
      failed-peers-cache-size = 100

      # Expire timeout for failed peer addresses in cache
      failed-peers-cache-expire-timeout = 10 minutes
    }
  }

  # NTP settings
  ntp {
    servers = ["0.pool.ntp.org", "1.pool.ntp.org", "2.pool.ntp.org", "3.pool.ntp.org"]

    # Socket timeout for synchonization request.
    request-timeout = 10 seconds

    # Time between synchronization requests.
    expiration-timeout = 1 minute

    # Maximum time without synchronization. Required for PoA consensus.
    # fatal-timeout = 1 minute
  }

  # P2P Network settings
  network {
    # Peers and blacklist storage file
    file = ${node.directory}"/peers.dat"

    # String with IP address and port to send as external address during handshake. Could be set automatically if UPnP
    # is enabled.
    #
    # If `declared-address` is set, which is the common scenario for nodes running in the cloud, the node will just
    # listen to incoming connections on `bind-address:port` and broadcast its `declared-address` to its peers. UPnP
    # is supposed to be disabled in this scenario.
    #
    # If declared address is not set and UPnP is not enabled, the node will not listen to incoming connections at all.
    #
    # If declared address is not set and UPnP is enabled, the node will attempt to connect to an IGD, retrieve its
    # external IP address and configure the gateway to allow traffic through. If the node succeeds, the IGD's external
    # IP address becomes the node's declared address.
    #
    # In some cases, you may both set `decalred-address` and enable UPnP (e.g. when IGD can't reliably determine its
    # external IP address). In such cases the node will attempt to configure an IGD to pass traffic from external port
    # to `bind-address:port`. Please note, however, that this setup is not recommended.
    # declared-address = "1.2.3.4:6864"

    # Network address
    bind-address = "0.0.0.0"

    # Port number
    port = 6864

    # Supported values: default, watcher
    mode = default

    # Node name to send during handshake. Comment this string out to set random node name.
    # node-name = "default-node-name"

    # Node nonce to send during handshake. Should be different if few nodes runs on the same external IP address. Comment this out to set random nonce.
    # nonce = 0

    # List of IP addresses of well known nodes.
    known-peers = []

    # How long the information about peer stays in database after the last communication with it
    peers-data-residence-time = 1d

    # How long peer stays in blacklist after getting in it
    black-list-residence-time = 15m

    # Breaks a connection if there is no message from the peer during this timeout
    break-idle-connections-timeout = 1m

    # How many simultaneous network connections can be made
    max-simultaneous-connections = 30

    # Attempt connection to peers delay
    attempt-connection-delay = 5s

    # Number of transaction that will be (used by UtxPool)
    tx-buffer-size = 10000

    # Timeout on network communication with other peers
    connection-timeout = 30s

    # If yes the node requests peers and sends known peers
    enable-peers-exchange = yes

    # If yes the node can blacklist others
    enable-blacklisting = yes

    # How often connected peers list should be requested
    peers-request-interval = 2m

    # When accepting connection from remote peer, this node will wait for handshake for no longer than this value. If
    # remote peer fails to send handshake within this interval, connection will be aborted. Likewise, when connecting to a
    # remote peer, this node will wait for handshake response for no longer than this value. If remote peer does not
    # respond in a timely manner, connection with hem will be aborted.
    handshake-timeout = 30s

    suspension-residence-time = 1m

    # When a new treansaction comes from the network, we cache it and doesn't push this transaction again when it comes
    # from another peer.
    # This setting setups a timeout to remove an expired transaction in the elimination cache.
    received-txs-cache-timeout = 3m

    upnp {
      # Enable UPnP tunnel creation only if you router/gateway supports it. Useful if your node is runnin in home
      # network. Completely useless if you node is in cloud.
      enable = no

      # UPnP timeouts
      gateway-timeout = 7s
      discover-timeout = 3s
    }

    # Logs incoming and outgoing messages
    traffic-logger {
      # Codes of transmitted messages to ignore. See MessageSpec.messageCode
      ignore-tx-messages = [23, 25] # BlockMessageSpec, TransactionMessageSpec

      # Codes of received messages to ignore. See MessageSpec.messageCode
      ignore-rx-messages = [25] # TransactionMessageSpec
    }
  }

  # Wallet settings
  wallet {
    # Path to wallet file
    file = ${node.directory}"/wallet/wallet.dat"

    # Password to protect wallet file
    password = "some string as password"

    # By default, the node will attempt to generate a new seed. To use a specific seed, uncomment the following line and
    # specify your base58-encoded seed.
    # seed = "BASE58SEED"
  }

  # Blockchain settings
  blockchain {
    # Blockchain type. Could be DEFAULT | CUSTOM. Default value is DEFAULT.
    type = DEFAULT

    consensus.type = PoS

    # 'custom' section present only if CUSTOM blockchain type is set. It's impossible to overwrite predefined 'default' configuration.
    #    custom {
    #      # Address feature character. Used to prevent mixing up addresses from different networks.
    #      address-scheme-character = "C"
    #
    #      # Timestamps/heights of activation/deactivation of different functions.
    #      functionality {
    #
    #        # Blocks period for feature checking and activation
    #        feature-check-blocks-period = 10000
    #
    #        # Blocks required to accept feature
    #        blocks-for-feature-activation = 9000
    #
    #        pre-activated-features {
    #          1 = 100
    #          2 = 200
    #        }
    #      }
    #
    #      # List of genesis transactions
    #      genesis {
    #        # Timestamp of genesis block and transactions in it
    #        timestamp = 1460678400000
    #
    #        # Genesis block signature
    #        signature = "BASE58BLOCKSIGNATURE"
    #
    #        # Initial balance in smallest units
    #        initial-balance = 100000000000000
    #
    #        # Initial base target
    #        initial-base-target =153722867
    #
    #        # Average delay between blocks
    #        average-block-delay = 60s
    #
    #        # List of genesis transactions
    #        transactions = [
    #          {recipient = "BASE58ADDRESS1", amount = 50000000000000},
    #          {recipient = "BASE58ADDRESS2", amount = 50000000000000}
    #        ]
    #      }
    #    }
    fees {
      base {
        issue = 1 WEST
        transfer = 0.01 WEST
        reissue = 1 WEST
        burn = 0.05 WEST
        exchange = 0.005 WEST
        lease = 0.01 WEST
        lease-cancel = 0.01 WEST
        create-alias = 1 WEST
        mass-transfer = 0.05 WEST
        data = 0.05 WEST
        set-script = 0.5 WEST
        sponsor-fee = 1 WEST
        set-asset-script = 1 WEST
        permit = 0.01 WEST
        create-contract = 1 WEST
        call-contract = 0.1 WEST
        disable-contract = 0.01 WEST
        update-contract = 1 WEST
        register-node = 0.01 WEST
        create-policy = 1 WEST
        update-policy = 0.5 WEST
        policy-data-hash = 0.05 WEST
      }

      additional {
        mass-transfer = 0.01 WEST
        data = 0.01 WEST
      }
    }
  }

  # New blocks generator settings
  miner {
    # Enable/disable block generation
    enable = yes

    # Required number of connections (both incoming and outgoing) to attempt block generation. Setting this value to 0
    # enables "off-line generation".
    quorum = 1

    # Enable block generation only in the last block is not older the given period of time
    interval-after-last-block-then-generation-is-allowed = 1d

    # Mining attempts delay, if no quorum available
    no-quorum-mining-delay = 5s

    # Interval between microblocks
    micro-block-interval = 5s

    # Max amount of transactions in micro block (but not bigger than 500)
    max-transactions-in-micro-block = 255

    # Max block size in bytes
    max-block-size-in-bytes = 1048576

    # Miner references the best microblock which is at least this age
    min-micro-block-age = 6s

    # Minimum time between key blocks (affects PoS only)
    minimal-block-generation-offset = 200ms

    # Size of transactions buffer. The higher the value of the parameter, the longer the transactions group.
    pulling-buffer-size = 100

    # Delay between checks for transactions in UTX pool, min value 100ms
    utx-check-delay = 1000ms
  }

  # Node's REST API settings
  api {
    rest {
      # Enable/disable REST API
      enable = yes

      # Network address to bind to
      bind-address = "0.0.0.0"

      # Port to listen to REST API requests
      port = 6862

      # Enable/disable CORS support
      cors = yes

      # Max number of transactions
      # returned by /transactions/address/{address}/limit/{limit}
      transactions-by-address-limit = 10000

      distribution-address-limit = 1000
    }

    grpc {
      # Enable/disable gRPC API
      enable = yes

      # Network address to bind to
      bind-address = "0.0.0.0"

      # Port to listen to gRPC API requests
      port = 6865

      # gRPC route BlockchainEventsService
      services {
        blockchain-events {
          # Max simultanious connections to route
          max-connections = 5

          history-events-buffer {
            enable: false
            size-in-bytes: 50MB
          }
        }

        # gRPC route PrivacyEventsService
        privacy-events {
          # Max simultanious connections to route
          max-connections = 5

          history-events-buffer {
            enable: false
            size-in-bytes: 50MB
          }
        }

        # gRPC route ContractStatusService
        contract-status-events {
          # Max simultanious connections to route
          max-connections = 5
        }
      }

      # Akka HTTP settings for gRPC server
      akka-http-settings {
        akka {
          http.server.idle-timeout = infinite

          # Uncomment these settings if you want detailed logging for gRPC calls
          # loggers = ["akka.event.slf4j.Slf4jLogger"]
          # loglevel = "DEBUG"
          # logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
          # stdout-loglevel = "DEBUG"
          # log-dead-letters = 10
          # log-dead-letters-during-shutdown = on
          #
          # actor {
          #   debug {
          #     # enable function of LoggingReceive, which is to log any received message at
          #     # DEBUG level
          #     receive = on
          #     # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill etc.)
          #     autoreceive = on
          #     # enable DEBUG logging of actor lifecycle changes
          #     lifecycle = on
          #     # enable DEBUG logging of unhandled messages
          #     unhandled = on
          #     # enable DEBUG logging of subscription changes on the eventStream
          #     event-stream = on
          #     # enable DEBUG logging of all LoggingFSMs for events, transitions and timers
          #     fsm = on
          #   }
          # }
          #
          # io.tcp.trace-logging = on
          # http.server.http2.log-frames = yes
        }
      }
    }

    # Authorization strategy should be either 'oauth2' or 'api-key', default is 'api-key'
    auth {
      type = "api-key"

      # Hash of API key string
      api-key-hash = "H6nsiifwYKYEx6YzYD7woP1XCn72RVvx6tC1zjjLXqsu"

      # Hash of API key string for PrivacyApi routes
      privacy-api-key-hash = "H6nsiifwYKYEx6YzYD7woP1XCn72RVvx6tC1zjjLXqsu"

      # Hash of API key string for ConfidentialContractsApi routes
      confidential-contracts-api-key-hash = "H6nsiifwYKYEx6YzYD7woP1XCn72RVvx6tC1zjjLXqsu"
    }
    # For OAuth2:
    # auth {
    #   type: "oauth2"

    #   # OAuth2 service public key to verify auth tokens
    #   public-key: "AuthorizationServicePublicKeyInBase64"

    # }
  }

  # Nodes synchronization settings
  synchronization {

    # How many block signatures are used to request an extension from peers.
    max-rollback = 100

    # How many block signatures are used to create a response with extension.
    max-chain-length = 101

    # How many blocks in batch are used to request an extension from peers.
    extension-batch-size = 10

    # Timeout to receive requested signatures or one extension block
    synchronization-timeout = 40s

    # Time to live for broadcasted score
    score-ttl = 90s

    # Settings for invalid blocks cache
    invalid-blocks-storage {
      # Maximum elements in cache
      max-size = 30000

      # Time to store invalid blocks and blacklist their owners in advance
      timeout = 5m
    }

    # History replier caching settings
    history-replier {
      # Max microblocks to cache
      max-micro-block-cache-size = 50

      # Max blocks to cache
      max-block-cache-size = 20
    }

    utx-synchronizer {
      # Max number of transactions in buffer. When the limit is reached, the node processes all transactions in batch
      max-buffer-size = 500

      # Max time for buffer. When time is out, the node processes all transactions in batch
      max-buffer-time = 500ms
    }

    transaction-broadcaster {
      # Required broadcast count per transaction. Must not exceed the number of nodes in the network - 1 (sender).
      min-broadcast-count = 2

      # Maximum number of channels for broadcasting one transaction.
      max-broadcast-count = 30

      # Max number of transactions in batch. When the limit is reached, the node processes all transactions in batch
      max-batch-size = 500

      # Max time for batch. When time is out, the node processes all transactions in batch
      max-batch-time = 500ms

      # Delay until next broadcast attempt
      retry-delay = 20s

      # Max count of known unconfirmed transaction in cache
      known-tx-cache-size = 100000

      # Max time an unconfirmed transaction lives in cache
      known-tx-cache-time = 20s

      # Interval between current miner list updates
      miners-update-interval = 1s
    }

    # MicroBlock synchronizer settings
    micro-block-synchronizer {
      # How much time to wait before a new request of a microblock will be done
      wait-response-timeout = 5s

      # How much time to remember processed microblock signatures
      processed-micro-blocks-cache-timeout = 3m

      # How much time to remember microblocks and their nodes to prevent same processing
      inventory-cache-timeout = 90s

      # Limits the size of cache for microblocks and inventories
      max-cache-size = 500

      # Max parallel micro-block crawling tasks count
      crawling-parallelism = 10

      # Maximum number of download attempts when the wait-response-timeout expires
      max-download-attempts = 3
    }

    key-block-appending {
      # Maximum number of key block appending attempts
      max-attempts = 10

      # Pause between key block appending attempts
      retry-interval = 400ms
    }
  }

  # Unverified transactions pool settings
  utx {
    # Memory limit, default - 1 GiB
    memory-limit = 100MiB
    # Utx cleanup task interval
    cleanup-interval = 5m
    # Allow transactions from smart accounts
    allow-transactions-from-smart-accounts = true
    # Txs rebroadcast time's threshold
    rebroadcast-threshold = 5m
    # Interval between rebroadcast of old txs
    rebroadcast-interval = 5m
  }

  additional-cache {
    rocksdb {
      # Limits the size of caches which are used during block validation. Lower values slightly decrease memory consummption,
      # while higher values might increase node performance. Setting ghis value to 0 disables caching alltogether.
      max-cache-size = 100000
      max-rollback-depth = 2000
    }

    confidential-rocksdb {
      max-rollback-depth = 2000
    }

    block-ids {
      max-size = 200
      expire-after = 10m
    }

    key-block-ids {
      max-size = 200
      expire-after = 10m
    }
  }

  features {
    auto-support-implemented-features = yes
    auto-shutdown-on-unsupported-feature = yes
    supported = []
  }

  # Doesn't have to be specified for Waves crypto
  # pki {
  #   tsp-server = "http://localhost/TSP/tsp.srf"
  # }

  # Docker smart contracts settings
  docker-engine {
    # Docker smart contracts enabled flag
    enable = no

    # Basic auth credentials for docker host (if it is behind some proxy, for example)
    # docker-auth {
    #   username = "some user"
    #   password = "some password"
    # }

    # Optional connection string to docker host for contracts execution.
    # If it is not set then it will be read from system environment
    # docker-host = "unix:///var/run/docker.sock"

    # Optional string to node REST API if remote docker host is used (set by 'docker-host' setting)
    # node-rest-api = "https://clinton.weservices.com/node-0"

    # Use the same docker host to start contracts containers this node application is started on.
    # Must be enabled, if node is started in docker container and 'docker-host' setting is not set
    use-node-docker-host = no

    # Maximum number of concurrently executing contracts
    contracts-parallelism = 8

    # Execution settings
    execution-limits {
      # Separate timeout for contract container startup
      startup-timeout = 20s
      # Contract execution timeout. Must be less than 'average-block-delay' for PoS or 'round-duration' for PoA
      timeout = 5s
      # Memory limit in Megabytes
      memory = 512
      # Memory swap value in Megabytes (see https://docs.docker.com/config/containers/resource_constraints/)
      memory-swap = 0
    }
    # Remove contract container after specified duration passed and no contract calls was during this time
    remove-container-after = 10m
    # Remote registries auth information
    remote-registries = []
    # Check registry auth on node startup
    check-registry-auth-on-startup = yes
    # Optional default registry domain to pull images from if just contract name is set
    # default-registry-domain = "registry.wvservices.com"
    # Contract execution messages cache settings
    contract-execution-messages-cache {
      # Maximum messages count in cache
      max-size = 100000
      # Time to expire for messages in cache
      expire-after = 60m
      # Max number of messages in buffer. When the limit is reached, the node processes all messages in batch
      max-buffer-size = 10
      # Max time for buffer. When time is out, the node processes all messages in batch
      max-buffer-time = 100ms
      # Interval between the utx pool cleanup for executable transactions with error status.
      utx-cleanup-interval = 1m
      # Required number of error statuses to remove a transaction from the utx pool.
      contract-error-quorum = 2
      # Propagate only failed execution messages
      ignore-successful = false
    }
    # Expiration time for token given to contract
    contract-auth-expires-in = 1m
    # gRPC server settings
    grpc-server {
      # Optional node host if we use remote docker host (set by 'docker-host' setting)
      #host = "192.168.65.2"
      port = 6865
    }
    # Remove (or not) container if it failed. Useful for debug
    remove-container-on-fail = yes
    # CircuitBreaker settings
    circuit-breaker {
      # The maximum count for allowed failures before opening the circuit breaker
      max-failures = 10
      # Limit on the number of open circuit-breaker events per contract. When the limit is exceeded, the contract transactions will be removed from the UTX.
      contract-opening-limit = 5
      # Limit on the opened circuit-breakers. When the limit is exceeded, transactions of all contracts will be removed from the UTX.
      opened-breakers-limit = 100
      # Time to expire for contract circuit-breaker if it hasn't got access during this time
      expire-after = 4h
      # The timespan to wait in the `Open` state before attempting a close of the circuit breaker
      reset-timeout = 5s
      # A factor to use for resetting the resetTimeout when in the `HalfOpen` state, in case the attempt for `Close` fails
      exponential-backoff-factor = 2
      # The maximum timespan the circuit breaker is allowed to use
      max-reset-timeout = 1m
    }
  }

  wasm {
    timeout = 500ms
  }

  # anchoring config
  anchoring {
    enable = no

    #    height-condition {
    #      range = 5
    #      above = 6
    #    }
    #
    #    threshold = 1

    #    targetnet {
    #       auth {
    #          type = "api-key" # "api-key" or "oauth2"
    #
    #          # type = "oauth2"
    #          # authorization-token = "xxxx"
    #          # authorization-service-url = "http://localhost:3000"
    #          # token-update-interval = "7 minutes"
    #       }
    #
    #       scheme-byte = "K"
    #       node-address = "http://node-1:6862"
    #       node-recipient-address = "3JWveBpXS1EcDpxcoAwVNAjFfUMrxaALgZt"
    #
    #       wallet {
    #         file = "targetnet-wallet.dat"
    #         password = "small"
    #       }
    #
    #       targetnet-fee = 500000
    #    }
    #
    #    sidechain-fee = 500000
  }

  # Consensual snapshot taking config
  consensual-snapshot {
    # Set to "yes" if you want to enable it
    enable = no
    # # Snapshot taking height (from this height blocks with transactions are not allowed)
    # snapshot-height = 12000000
    # Blocks count to wait for state stability and to start snapshot sending
    wait-blocks-count = 10
    # Back-off settings for error case
    back-off {
      # Max retries count for snapshot task
      max-retries = 3
      # Initial delay for exponetial back-off
      delay = 10m
    }
    # # Consensus type for snapshot genesis block (PoA or CFT)
    # consensus-type = CFT
  }

  health-check {
    enable = true
    interval = 30s
    timeout = 10s
  }
}

# Performance metrics
kamon {
  # Set to "yes", if you want to report metrics
  enable = no

  # A node identification
  environment {
    service = "waves-node"

    # An unique id of your node to distinguish it from others
    # host = ""
  }

  # An interval within metrics are aggregated. After it, them will be sent to the server
  metric.tick-interval = 10 seconds

  # Reporter settings
  influxdb {
    hostname = "127.0.0.1"
    port = 8086
    database = "mydb"

    # authentication {
    #   user = ""
    #   password = ""
    # }
  }

  modules {
    jvm-metrics.enabled = no
    process-metrics.enabled = no
    host-metrics.enabled = no
  }
}

# Non-aggregated data (information about blocks, transactions, ...)
metrics {
  enable = no
  node-id = -1 # ${kamon.environment.host}
  node-id = ${?HOSTNAME}

  influx-db {
    uri = "http://"${kamon.influxdb.hostname}":"${kamon.influxdb.port}
    db = ${kamon.influxdb.database}

    # username = ${kamon.influxdb.authentication.user}
    # password = ${kamon.influxdb.authentication.password}

    batch-actions = 100
    batch-flash-duration = 5s
  }
  # Enabled metrics by default
  segments = [
    "common",
    "block",
    "privacy",
    "contract",
    "contract-validation",
    "poa"
  ]

  circuit-breaker-cache {
    # Maximum size of circuit breaker's counters cache
    max-size = 300

    # Maximum contract image tag lifetime without activity
    expire-after = 10m
  }

  http-requests-cache {
    # Maximum size of request tags cache
    max-size = 300

    # Maximum request tag lifetime without activity
    expire-after = 1m
  }
}

# WARNING: No user-configurable settings below this line.

akka {
  loglevel = "INFO"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters-during-shutdown = false

  # For better support of shutdown process, implement an additional step in a coordinated shutdown:
  # https://doc.akka.io/docs/akka/2.5/actors.html?language=scala#coordinated-shutdown
  jvm-shutdown-hooks = off

  actor {
    allow-java-serialization = off
    guardian-supervisor-strategy = "com.wavesenterprise.actor.RootActorSystem$EscalatingStrategy"
  }

  http.server {
    max-connections = 128
    parsing {
      max-method-length = 64
      max-content-length = 3m
    }
  }

  io.tcp {
    direct-buffer-size = 1536 KiB
    trace-logging = off
  }
}

# Application for starting node from snapshot state
snapshot-starter-app {

  logging-level = "DEBUG"

  # Timeout to receiving response for request
  request-timeout = 30s

  # Delay between peer switching
  peer-selection-delay = 10s

  # Delay when the peers are over
  peer-loop-retry-delay = 10s

  # Max snapshot download loop retries
  max-retries = 2
}
